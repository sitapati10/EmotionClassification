{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "931d6563bad54573bc9e2ba2c734e2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c105bce765748a88128076f76ec1b1f",
              "IPY_MODEL_86e8a2915bd94a63ac980fe31b2c68c3",
              "IPY_MODEL_6f8b431e5e9b4651b153de438c142055"
            ],
            "layout": "IPY_MODEL_5bd23b6016684e3c869e9228fb52e0fe"
          }
        },
        "2c105bce765748a88128076f76ec1b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a2b5ab0240462fbe51676b8b7ed478",
            "placeholder": "​",
            "style": "IPY_MODEL_4809baa688044b398c9ff7100f4db297",
            "value": "vocab.json: 100%"
          }
        },
        "86e8a2915bd94a63ac980fe31b2c68c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea14b8deb56482ab7b115e4f25c8c8c",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_671f2aa2b3904886a6daecd69497e763",
            "value": 898822
          }
        },
        "6f8b431e5e9b4651b153de438c142055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbcf0932d99f4a58be7db5449fa00d58",
            "placeholder": "​",
            "style": "IPY_MODEL_110cae555cfb4c06b5e048eac8f6a4d0",
            "value": " 899k/899k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "5bd23b6016684e3c869e9228fb52e0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a2b5ab0240462fbe51676b8b7ed478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4809baa688044b398c9ff7100f4db297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ea14b8deb56482ab7b115e4f25c8c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "671f2aa2b3904886a6daecd69497e763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbcf0932d99f4a58be7db5449fa00d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110cae555cfb4c06b5e048eac8f6a4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306e9042f70d4409a816523dc9cb8661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1255a4c72d643d2a46e6c137850fe1f",
              "IPY_MODEL_1995644087a343008fb38a11295e4a80",
              "IPY_MODEL_70a34d5b89934c768900bb9180472e8c"
            ],
            "layout": "IPY_MODEL_269452853b874f02af94c9f16c0733dc"
          }
        },
        "f1255a4c72d643d2a46e6c137850fe1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f69f51e4a64dd1a4fbb8387f9d7ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_3c518d0f5d1d4fdfa3f547506316da07",
            "value": "merges.txt: 100%"
          }
        },
        "1995644087a343008fb38a11295e4a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0c4279ec0842639e00bb7330539815",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_397d06db4f114dc8ba311c318bd0e2a7",
            "value": 456318
          }
        },
        "70a34d5b89934c768900bb9180472e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8095603c43ff4c1994d6da615a747b72",
            "placeholder": "​",
            "style": "IPY_MODEL_4918c5f2fb804a5b97d563c2eb8d8892",
            "value": " 456k/456k [00:00&lt;00:00, 21.2MB/s]"
          }
        },
        "269452853b874f02af94c9f16c0733dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f69f51e4a64dd1a4fbb8387f9d7ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c518d0f5d1d4fdfa3f547506316da07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f0c4279ec0842639e00bb7330539815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397d06db4f114dc8ba311c318bd0e2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8095603c43ff4c1994d6da615a747b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4918c5f2fb804a5b97d563c2eb8d8892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0194e32012d49b8aa85055be40fd962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4225110c8216465c9cc821890dbdf305",
              "IPY_MODEL_1f4f872e7a344712b28116efc045976e",
              "IPY_MODEL_e470003c34f14555a1c6e17797c11459"
            ],
            "layout": "IPY_MODEL_ca792b608998452c8a8f65d50075bb2f"
          }
        },
        "4225110c8216465c9cc821890dbdf305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b38b39695a4f8ca91c25dd6782c97e",
            "placeholder": "​",
            "style": "IPY_MODEL_af2347616de74b15827664dd5525f13d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1f4f872e7a344712b28116efc045976e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c18b11ea6d44a74a747689f87593395",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92c4e159c26f49d1b3bb8d758b747c82",
            "value": 150
          }
        },
        "e470003c34f14555a1c6e17797c11459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc02df563a344aba34d4321426a91e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef1c1e86ecc4ca8a7520192a7ef6098",
            "value": " 150/150 [00:00&lt;00:00, 7.45kB/s]"
          }
        },
        "ca792b608998452c8a8f65d50075bb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b38b39695a4f8ca91c25dd6782c97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2347616de74b15827664dd5525f13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c18b11ea6d44a74a747689f87593395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c4e159c26f49d1b3bb8d758b747c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dc02df563a344aba34d4321426a91e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef1c1e86ecc4ca8a7520192a7ef6098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3b15f9bafc4b899e8aee0bffc54285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faa44895f9464cb8b1a491f2f3b7d610",
              "IPY_MODEL_2ad2f51c82e6453dbfb5bda9b9d4d494",
              "IPY_MODEL_47e5d511d06c417aa486d3359dd6327d"
            ],
            "layout": "IPY_MODEL_2f90d9eb7d1f447fb35b7700ecb0a515"
          }
        },
        "faa44895f9464cb8b1a491f2f3b7d610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d17b381e13f8467fae86ccb723a1c243",
            "placeholder": "​",
            "style": "IPY_MODEL_180c79e05dd5476585352cdce62c22bf",
            "value": "config.json: 100%"
          }
        },
        "2ad2f51c82e6453dbfb5bda9b9d4d494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c9596824474a3884c87bcca6750332",
            "max": 768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f433b1481af24ae99f7bac5af65ecaef",
            "value": 768
          }
        },
        "47e5d511d06c417aa486d3359dd6327d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bacdf15feaa4c72bd04da2c1d324738",
            "placeholder": "​",
            "style": "IPY_MODEL_472e16caf5f84060a19be7bef1fd3e0c",
            "value": " 768/768 [00:00&lt;00:00, 54.3kB/s]"
          }
        },
        "2f90d9eb7d1f447fb35b7700ecb0a515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17b381e13f8467fae86ccb723a1c243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180c79e05dd5476585352cdce62c22bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c9596824474a3884c87bcca6750332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f433b1481af24ae99f7bac5af65ecaef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bacdf15feaa4c72bd04da2c1d324738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472e16caf5f84060a19be7bef1fd3e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60339f04a0f3439986c5e800ff169ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bbd0c2b87704468b0abf99b58ce0ea1",
              "IPY_MODEL_c900e7edb64049f694f138f438fba18d",
              "IPY_MODEL_b89de17dad75432d97f6671b35052948"
            ],
            "layout": "IPY_MODEL_56b14535aabe41e1a6204f6d2896f5f5"
          }
        },
        "2bbd0c2b87704468b0abf99b58ce0ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a566520ccade4596a2de23d628689e5b",
            "placeholder": "​",
            "style": "IPY_MODEL_020a957349cb48ee8f1aa38860ab9fdc",
            "value": "tf_model.h5: 100%"
          }
        },
        "c900e7edb64049f694f138f438fba18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_732a8ac4f9004526ba7434afcece1663",
            "max": 501233376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8da2db33e9ac48a489f00e84a79a874b",
            "value": 501233376
          }
        },
        "b89de17dad75432d97f6671b35052948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05148b42492642d99b455e184d7b0410",
            "placeholder": "​",
            "style": "IPY_MODEL_84c66754db5f42ada803d1e3c3e3da98",
            "value": " 501M/501M [00:02&lt;00:00, 239MB/s]"
          }
        },
        "56b14535aabe41e1a6204f6d2896f5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a566520ccade4596a2de23d628689e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020a957349cb48ee8f1aa38860ab9fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "732a8ac4f9004526ba7434afcece1663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da2db33e9ac48a489f00e84a79a874b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05148b42492642d99b455e184d7b0410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c66754db5f42ada803d1e3c3e3da98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHpWuKDM25Kc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow numpy librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_folder(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Specify the path to the zip file and the directory where you want to extract the contents\n",
        "zip_file_path = '/content/drive/MyDrive/AudioWAV.zip'\n",
        "extracted_folder_path = 'Audio'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "\n",
        "# Call the function to unzip the folder\n",
        "unzip_folder(zip_file_path, extracted_folder_path)\n",
        "\n",
        "print(f\"Folder '{zip_file_path}' has been successfully extracted to '{extracted_folder_path}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfEPToPwnDhj",
        "outputId": "810be6bb-a6c0-4db9-c70e-007df020de47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/drive/MyDrive/AudioWAV.zip' has been successfully extracted to 'Audio'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Specify the path for the new folder\n",
        "folder_path = \"/content/AudioWithCategorisedWAV/\"\n",
        "\n",
        "folders = ['Anger','Disgust','Fear','Happy','Neutral','Sad']\n",
        "\n",
        "for i in folders:\n",
        "  folder_path1 = folder_path + i\n",
        "  if not os.path.exists(folder_path1):\n",
        "    os.makedirs(folder_path1)"
      ],
      "metadata": {
        "id": "GY4tQFLhuK6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import shutil\n",
        "#sourcepath = '/content/AudioInput'\n",
        "sourcepath = '/content/Audio/AudioWAV'\n",
        "destinationpath = '/content/AudioWithCategorisedWAV'\n",
        "files = os.listdir(sourcepath)\n",
        "\n",
        "for file in files:\n",
        "    source_file = os.path.join(sourcepath, file)\n",
        "    if not '.wav' in file:\n",
        "      continue\n",
        "    if 'ANG' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Anger', file)\n",
        "      shutil.move(source_file, destination_file)\n",
        "    elif 'DIS' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Disgust', file)\n",
        "      shutil.move(source_file, destination_file)\n",
        "    elif 'FEA' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Fear', file)\n",
        "      shutil.move(source_file, destination_file)\n",
        "    elif 'HAP' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Happy', file)\n",
        "      shutil.move(source_file, destination_file)\n",
        "    elif 'NEU' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Neutral', file)\n",
        "      shutil.move(source_file, destination_file)\n",
        "    elif 'SAD' in file:\n",
        "      destination_file = os.path.join(destinationpath+'/Sad', file)\n",
        "      shutil.move(source_file, destination_file)"
      ],
      "metadata": {
        "id": "9CkROAZGUSCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.70):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "def higher_speed(data, speed_factor = 1.25):\n",
        "    return librosa.effects.time_stretch(data, rate = speed_factor)\n",
        "\n",
        "def lower_speed(data, speed_factor = 0.75):\n",
        "    return librosa.effects.time_stretch(data, rate = speed_factor)"
      ],
      "metadata": {
        "id": "QScm4dV9c-xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to extract audio features using librosa\n",
        "def extract_features(audio, sample_rate, mfcc=True, chroma=True, mel=True):\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate), axis=1)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate), axis=1)\n",
        "        result = np.hstack((result, mel))\n",
        "    return result\n",
        "\n",
        "# Function to load audio data and labels\n",
        "def load_data(data_path):\n",
        "    features, labels = [], []\n",
        "    for folder in os.listdir(data_path):\n",
        "        label = folder\n",
        "        for file_name in os.listdir(os.path.join(data_path, folder)):\n",
        "            file_path = os.path.join(data_path, folder, file_name)\n",
        "            audio, sample_rate = librosa.load(file_path)\n",
        "            feature = extract_features(audio,sample_rate)\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "            #noised\n",
        "            noise_data = noise(audio)\n",
        "            feature = extract_features(noise_data,sample_rate)\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "            #stretched\n",
        "            #stretch_data = stretch(audio)\n",
        "            #feature = extract_features(stretch_data,sample_rate)\n",
        "            #features.append(feature)\n",
        "            #labels.append(label)\n",
        "            #pitched\n",
        "            #pitch_data = pitch(data = audio, sampling_rate = sample_rate)\n",
        "            #feature = extract_features(pitch_data,sample_rate)\n",
        "            #features.append(feature)\n",
        "            #labels.append(label)\n",
        "\n",
        "            #speed up\n",
        "            higher_speed_data = higher_speed(audio)\n",
        "            feature = extract_features(higher_speed_data,sample_rate)\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "\n",
        "            #speed down\n",
        "            lower_speed_data = higher_speed(audio)\n",
        "            feature = extract_features(lower_speed_data,sample_rate)\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Load data and preprocess\n",
        "data_path = \"/content/AudioWithCategorisedWAV\"\n",
        "features, labels = load_data(data_path)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n"
      ],
      "metadata": {
        "id": "gzNMExwJUqrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.1, random_state=42)\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(layers.Conv1D(256, kernel_size=3, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Recurrent layers\n",
        "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True)))\n",
        "model.add(layers.Bidirectional(layers.LSTM(128)))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['accuracy'],run_eagerly=True)\n"
      ],
      "metadata": {
        "id": "mf_ppqxFVLU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_labels = np.unique(labels)\n",
        "class_indices = {label: index for index, label in enumerate(class_labels)}\n",
        "Y = np.array([class_indices[label] for label in labels])\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(class_weight ='balanced',classes = np.unique(Y),y= Y)\n",
        "\n",
        "# Convert class weights to a dictionary for class_weight parameter in model.fit\n",
        "class_weights_dict = {class_index: weight for class_index, weight in zip(np.unique(Y), class_weights)}\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "8LE8j3TTVQDN",
        "outputId": "365645e6-5173-4f8d-d158-fc2e2ef915ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "838/838 [==============================] - 703s 837ms/step - loss: 1.4689 - accuracy: 0.3906 - val_loss: 1.7724 - val_accuracy: 0.2781\n",
            "Epoch 2/50\n",
            "838/838 [==============================] - 710s 847ms/step - loss: 1.3680 - accuracy: 0.4429 - val_loss: 2.3436 - val_accuracy: 0.1683\n",
            "Epoch 3/50\n",
            " 26/838 [..............................] - ETA: 10:10 - loss: 1.3474 - accuracy: 0.4615"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-24ebc68273a3>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclass_weights_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 )\n\u001b[1;32m   1383\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1679\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1680\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1681\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4069\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4071\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    541\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_TanhGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# y = tanh(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miterable_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_iterable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotion_classification_Audio_model.h5\")\n",
        "\n",
        "# Optionally, you can also save the weights only\n",
        "model.save_weights(\"emotion_classification_model_Audio_weights.h5\")"
      ],
      "metadata": {
        "id": "QhwQugYuVjaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbc999c-9434-47cb-b450-2577783ba1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_folder(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Specify the path to the zip file and the directory where you want to extract the contents\n",
        "zip_file_path = '/content/drive/MyDrive/VideoFlash.zip'\n",
        "extracted_folder_path = 'Videos'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "\n",
        "# Call the function to unzip the folder\n",
        "unzip_folder(zip_file_path, extracted_folder_path)\n",
        "\n",
        "print(f\"Folder '{zip_file_path}' has been successfully extracted to '{extracted_folder_path}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hncXBrCO2tfC",
        "outputId": "cef4b607-435c-4e4a-d534-5765f3a90246"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/drive/MyDrive/VideoFlash.zip' has been successfully extracted to 'Videos'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import shutil\n",
        "def preprocess_frame(frame):\n",
        "    # Preprocess the frame: resize, normalize, etc.\n",
        "    processed_frame = cv2.resize(frame, (224, 224))\n",
        "    processed_frame = processed_frame / 255.0  # Normalize pixel values\n",
        "    return processed_frame\n",
        "\n",
        "def read_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed_frame = preprocess_frame(frame)\n",
        "\n",
        "    cap.release()\n",
        "    return processed_frame"
      ],
      "metadata": {
        "id": "JZyvai3v3xWe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourcepath = '/content/Videos/VideoFlash'\n",
        "files = os.listdir(sourcepath)\n",
        "xdata = []\n",
        "ylabels = []\n",
        "\n",
        "for file in files:\n",
        "    source_file = os.path.join(sourcepath, file)\n",
        "    xdata.append(read_video(source_file))\n",
        "    if 'ANG' in file:\n",
        "      ylabels.append('Ang')\n",
        "    elif 'DIS' in file:\n",
        "      ylabels.append('DIS')\n",
        "    elif 'FEA' in file:\n",
        "      ylabels.append('FEA')\n",
        "    elif 'HAP' in file:\n",
        "      ylabels.append('HAP')\n",
        "    elif 'NEU' in file:\n",
        "      ylabels.append('NEU')\n",
        "    elif 'SAD' in file:\n",
        "      ylabels.append('SAD')\n",
        "\n",
        "xdata1 = np.array(xdata)"
      ],
      "metadata": {
        "id": "Hk6VlqhLVne4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(xdata1, ylabels, test_size=0.2, random_state=42)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse = False)\n",
        "y_train_onehot = onehot_encoder.fit_transform((np.array(y_train1)).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "mqChL-F9w9U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load the VGG19 model without the fully connected layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add your own fully connected layers for emotion classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(6, activation='softmax')(x)  # Add your number of emotion classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],run_eagerly=True)\n"
      ],
      "metadata": {
        "id": "9rzGjz4saZJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = np.unique(y_train1)\n",
        "class_indices = {label: index for index, label in enumerate(class_labels)}\n",
        "Y = np.array([class_indices[label] for label in y_train1])\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(class_weight ='balanced',classes = np.unique(Y),y= Y)\n",
        "\n",
        "# Convert class weights to a dictionary for class_weight parameter in model.fit\n",
        "class_weights_dict = {class_index: weight for class_index, weight in zip(np.unique(Y), class_weights)}\n",
        "\n",
        "model.fit(x=X_train1,y=y_train_onehot,batch_size=8,epochs=20, class_weight=class_weights_dict)"
      ],
      "metadata": {
        "id": "D-yL-92Gal5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotion_classification_Video_model.h5\")\n",
        "\n",
        "# Optionally, you can also save the weights only\n",
        "model.save_weights(\"emotion_classification_model_Video_weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5GTkM4sepUn",
        "outputId": "a4fd849c-e018-404a-8567-df1f11665529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install nltk\n",
        "#!pip install transformers\n",
        "#!pip install --upgrade protobuf\n",
        "#!pip install --upgrade tensorflow --user"
      ],
      "metadata": {
        "id": "b-sGdneokuUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed64759-9029-4961-8dcd-1ebf7e8bd714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tabulate import tabulate\n"
      ],
      "metadata": {
        "id": "_aepoadooo1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQk_LIqWQ_bx",
        "outputId": "ce305847-1f42-4911-92d2-cc22864a67a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = pd.read_csv('tweet_emotions.csv')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def expand_contractions(text):\n",
        "    '''\n",
        "    Function replaces abbreviations with full word versions\n",
        "    '''\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def clean_content(text):\n",
        "\n",
        "    text = expand_contractions(text)\n",
        "    # remove twitter handles\n",
        "    clean_text = re.sub(r'@\\w+\\s?', '', text)\n",
        "\n",
        "    # convert to lowercase\n",
        "    clean_text = clean_text.lower()\n",
        "\n",
        "    # remove links http:// or https://\n",
        "    clean_text = re.sub(r'https?:\\/\\/\\S+', '', clean_text)\n",
        "\n",
        "    # remove links beginning with www. and ending with .com\n",
        "    clean_text = re.sub(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', '', clean_text)\n",
        "\n",
        "    # remove html reference characters\n",
        "    clean_text = re.sub(r'&[a-z]+;', '', clean_text)\n",
        "\n",
        "    # remove non-letter characters besides spaces \"/\", \";\" \"[\", \"]\" \"=\", \"#\"\n",
        "    clean_text = re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', clean_text)\n",
        "    clean_text = clean_text.split()\n",
        "\n",
        "    # remove stop words\n",
        "    clean_lst = []\n",
        "    for word in clean_text:\n",
        "      if word not in stop_words:\n",
        "        clean_lst.append(word)\n",
        "\n",
        "\n",
        "    lemmatized_words = []\n",
        "    for word in clean_lst:\n",
        "      lemmatized_word = WordNetLemmatizer().lemmatize(word)\n",
        "      lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "df_clean['content'] = df_clean['content'].apply(lambda x :  clean_content(x))\n",
        "\n",
        "# delete duplicates\n",
        "df_clean.drop_duplicates(subset='content', inplace=True)\n",
        "#df_clean.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# delete small sentence\n",
        "df_clean = df_clean.loc[df_clean['content'].apply(lambda x: len(x) >= 3)]\n",
        "\n",
        "# splitting into tokens, features of the structure of the text used in Twitter\n",
        "df_clean['content'] = df_clean['content'].apply(TweetTokenizer().tokenize)\n",
        "\n",
        "# remove punctuation marks\n",
        "PUNCUATION_LIST = list(string.punctuation)\n",
        "def remove_punctuation(word_list):\n",
        "    return [w for w in word_list if w not in PUNCUATION_LIST]\n",
        "df_clean['content'] = df_clean['content'].apply(remove_punctuation)\n",
        "df_clean['content'] = df_clean['content'].apply(lambda x: ' '.join(x))\n",
        "df_clean['sentiment'] = df_clean['sentiment'].replace(['happiness', 'enthusiasm', 'surprise','love'], 'Happy')\n",
        "df_clean['sentiment'] = df_clean['sentiment'].replace(['boredom','sadness','Sad'], 'sad')\n",
        "df_clean['sentiment'] = df_clean['sentiment'].replace(['hate','anger'], 'Anger')\n",
        "df_clean['sentiment'] = df_clean['sentiment'].replace(['relief', 'empty', 'Neutral'], 'neutral')\n",
        "X_train, X_test, y_train, y_test= train_test_split(df_clean['content'], df_clean['sentiment'], test_size=0.2, random_state=42)\n",
        "onehot_encoder = OneHotEncoder(sparse = False)\n",
        "y_train_onehot = onehot_encoder.fit_transform((np.array(df_clean['sentiment'])).reshape(-1, 1))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder instance\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder and transform the categories into numerical labels\n",
        "y_label_encoder = label_encoder.fit_transform(df_clean['sentiment'])"
      ],
      "metadata": {
        "id": "xuGComB0RBD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "tokenizer_roberta = RobertaTokenizerFast.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "\n",
        "#ros = RandomOverSampler()\n",
        "#x_train, y_train = ros.fit_resample(np.array(df_clean['content']).reshape(-1, 1), np.array(df_clean['sentiment']).reshape(-1, 1))\n",
        "#train_os = pd.DataFrame(list(zip([x[0] for x in x_train], y_train)), columns = ['content', 'sentiment'])\n",
        "X_train = df_clean['content'].values\n",
        "y_train = df_clean['sentiment'].values\n",
        "\n",
        "y_train = OneHotEncoder().fit_transform(np.array(y_train).reshape(-1, 1)).toarray()\n",
        "\n",
        "token_lens = []\n",
        "\n",
        "for txt in X_train:\n",
        "    tokens = tokenizer_roberta.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "max_length=np.max(token_lens)\n",
        "\n",
        "MAX_LEN=128\n",
        "\n",
        "def tokenize_roberta(data, max_len=MAX_LEN) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer_roberta.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids),np.array(attention_masks)\n",
        "\n",
        "train_inputs, train_masks = tokenize_roberta(X_train, MAX_LEN)\n",
        "\n",
        "\n",
        "roberta_model = TFRobertaModel.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "callbacks = [EarlyStopping(monitor='val_categorical_accuracy', patience=5, min_delta=0.01),\n",
        "             ModelCheckpoint(filepath='best_model.h5', monitor='val_categorical_accuracy', save_best_only=True)]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0gwEifWRd1M",
        "outputId": "d16104e4-b228-4780-f7bd-cc3605f356fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion were not used when initializing TFRobertaModel: ['classifier']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(bert_model, max_len=MAX_LEN):\n",
        "    inputs = Input(shape=(max_len,), dtype='int32')\n",
        "    masks = Input(shape=(max_len,), dtype='int32')\n",
        "\n",
        "    bert_output = bert_model([inputs, masks])[1]\n",
        "\n",
        "    dense_1 = Dense(128, activation='relu')(bert_output)\n",
        "    dropout_1 = Dropout(0.5)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(64, activation='relu')(dropout_1)\n",
        "    dropout_2 = Dropout(0.5)(dense_2)\n",
        "\n",
        "    output = Dense(6, activation='softmax')(dropout_2)\n",
        "\n",
        "    model = Model(inputs=[inputs, masks], outputs=output)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss=CategoricalCrossentropy(),\n",
        "                  metrics=CategoricalAccuracy())\n",
        "    return model\n",
        "\n",
        "model = create_model(roberta_model, MAX_LEN)\n",
        "history = model.fit([train_inputs, train_masks],y_train,epochs=4,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMbydr8Kz5X0",
        "outputId": "4e2d8ffb-39bd-4ecc-da33-f6fb66abd9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1197/1197 [==============================] - 989s 794ms/step - loss: 1.5376 - categorical_accuracy: 0.3825\n",
            "Epoch 2/4\n",
            "1197/1197 [==============================] - 949s 793ms/step - loss: 1.4577 - categorical_accuracy: 0.4261\n",
            "Epoch 3/4\n",
            "1197/1197 [==============================] - 949s 793ms/step - loss: 1.4126 - categorical_accuracy: 0.4523\n",
            "Epoch 4/4\n",
            "1197/1197 [==============================] - 949s 792ms/step - loss: 1.3709 - categorical_accuracy: 0.4757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotion_classification_Text_model.h5\")\n",
        "\n",
        "# Optionally, you can also save the weights only\n",
        "model.save_weights(\"emotion_classification_model_Text_weights.h5\")"
      ],
      "metadata": {
        "id": "vlkIkbyLSDQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_model = TFRobertaModel.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "roberta_model.predict([tokenize_roberta([\"It's eleven o'clock 😔\"])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbfXKh3NiQVr",
        "outputId": "35d86447-41a5-4ae6-c692-ccd98be5b2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02356157, 0.04002122, 0.01045423, 0.04828082, 0.55280364,\n",
              "        0.32487854]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[30:45]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG9xDFRxkba_",
        "outputId": "098a1e3c-550a-4784-97e9-9bb18a69de1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(df_clean['sentiment'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDg1PkuoIX9",
        "outputId": "9b389c8d-291d-4a0c-a16b-d92e07d5d047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Anger', 'Happy', 'fun', 'neutral', 'sad', 'worry'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OneHotEncoder().fit(np.array(df_clean['sentiment'].values).reshape(-1, 1)).get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvG6L-83oKxp",
        "outputId": "a16767c4-c35e-4cf9-e4d5-1363b6d2f620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['x0_Anger', 'x0_Happy', 'x0_fun', 'x0_neutral', 'x0_sad',\n",
              "       'x0_worry'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the entire model\n",
        "#Text_model = load_model(\"/content/emotion_classification_Text_model.h5\")\n",
        "Audio_model = load_model(\"/content/emotion_classification_Audio_model.h5\")\n",
        "Video_model = load_model(\"/content/emotion_classification_Video_model.h5\")"
      ],
      "metadata": {
        "id": "B1ce5M9nrq7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Video_model.predict(np.array([read_video('/content/1001_IEO_SAD_LO.flv')]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPQmCACn2GnI",
        "outputId": "2a1a163b-70e7-468b-fdb4-b38dc20199ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.1434891e-01, 1.0206088e-01, 4.4348928e-01, 2.7667569e-05,\n",
              "        2.5584141e-02, 1.1448909e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(Video_model.predict(np.array([read_video('/content/1001_IEO_SAD_LO.flv')])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdloBSaU4bBG",
        "outputId": "5978f64e-1388-4fa7-9f81-ac5783934593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = model\n",
        "text_model.predict([tokenize_roberta([\"It's eleven o'clock 😔\"])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg8lxPO_qnXY",
        "outputId": "5c7b8ce9-48f9-4235-d97a-6d03d9b9cc33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02356157, 0.04002122, 0.01045423, 0.04828082, 0.55280364,\n",
              "        0.32487854]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import cv2\n",
        "import librosa\n",
        "\n",
        "# Function to extract features from video\n",
        "def extract_video_features(video_path):\n",
        "    # Your video feature extraction code here\n",
        "    # Example: Using OpenCV to extract color histogram features\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed_frame = cv2.resize(frame, (224, 224))\n",
        "        processed_frame = processed_frame / 255.0  # Normalize pixel values\n",
        "\n",
        "    cap.release()\n",
        "    return processed_frame\n",
        "\n",
        "# Function to extract features from audio\n",
        "def extract_audio_features(file_path, mfcc=True, chroma=True, mel=True):\n",
        "    # Your audio feature extraction code here\n",
        "    # Example: Using librosa to extract MFCC features\n",
        "    audio, sample_rate = librosa.load(file_path)\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate), axis=1)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate), axis=1)\n",
        "        result = np.hstack((result, mel))\n",
        "    return result\n",
        "\n",
        "# Load your pre-trained text model (replace with your actual model loading code)\n",
        "def predict_text_emotion(text):\n",
        "    # Your text prediction code here\n",
        "    # Example: Using a simple RandomForestClassifier\n",
        "    # You should replace this with your actual text classification model\n",
        "    return text_model.predict([tokenize_roberta([text])])[0]\n",
        "\n",
        "# Load your pre-trained video model (replace with your actual model loading code)\n",
        "def predict_video_emotion(video_path):\n",
        "    # Your video prediction code here\n",
        "    # Example: Extract video features and use a simple RandomForestClassifier\n",
        "    video_features = extract_video_features(video_path)\n",
        "    return Video_model.predict(np.array([video_features]))\n",
        "\n",
        "# Load your pre-trained audio model (replace with your actual model loading code)\n",
        "def predict_audio_emotion(audio_path):\n",
        "    # Your audio prediction code here\n",
        "    # Example: Extract audio features and use a simple RandomForestClassifier\n",
        "    audio_features = extract_audio_features(audio_path)\n",
        "    return Audio_model.predict(np.array([audio_features]))\n",
        "\n",
        "# Example usage\n",
        "text_path = \"It's eleven o'clock 😔\"\n",
        "video_path = \"/content/1064_IEO_SAD_HI.flv\"\n",
        "audio_path = \"/content/1064_IEO_SAD_HI.wav\"\n",
        "\n",
        "# Let's assume your text, video, and audio models have predicted the following emotions\n",
        "text_emotion = predict_text_emotion(text_path)  # Example prediction from the text model\n",
        "video_emotion = predict_video_emotion(video_path)#[0.1, 0.4, 0.1, 0.1, 0.1, 0.2]  # Example prediction from the video model\n",
        "audio_emotion = predict_audio_emotion(audio_path)#[0.3, 0.2, 0.2, 0.1, 0.1, 0.1]  # Example prediction from the audio model\n",
        "\n",
        "# Set custom weights for each modality\n",
        "text_weight = 0.8\n",
        "video_weight = 0.2\n",
        "audio_weight = 0.3\n",
        "\n",
        "# Apply custom weights to each modality's prediction\n",
        "weighted_text_emotion = text_weight * np.array(text_emotion)\n",
        "weighted_video_emotion = video_weight * np.array(video_emotion)\n",
        "weighted_audio_emotion = audio_weight * np.array(audio_emotion)\n",
        "\n",
        "# Combine the weighted predictions (you can choose a different method, e.g., averaging)\n",
        "final_emotion = np.argmax(weighted_text_emotion + weighted_video_emotion + weighted_audio_emotion)\n",
        "\n",
        "print(\"Weighted Text Emotion:\", np.argmax(weighted_text_emotion))\n",
        "print(\"Weighted Video Emotion:\", np.argmax(weighted_video_emotion))\n",
        "print(\"Weighted Audio Emotion:\", np.argmax(weighted_audio_emotion))\n",
        "print(\"Final Emotion Class:\", final_emotion)\n"
      ],
      "metadata": {
        "id": "uB9CEyFO5RUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.optimizers import Adam\n",
        "def create_model(bert_model, max_len=128):\n",
        "    inputs = Input(shape=(max_len,), dtype='int32')\n",
        "    masks = Input(shape=(max_len,), dtype='int32')\n",
        "\n",
        "    bert_output = bert_model([inputs, masks])[1]\n",
        "\n",
        "    dense_1 = Dense(128, activation='relu')(bert_output)\n",
        "    dropout_1 = Dropout(0.5)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(64, activation='relu')(dropout_1)\n",
        "    dropout_2 = Dropout(0.5)(dense_2)\n",
        "\n",
        "    output = Dense(6, activation='softmax')(dropout_2)\n",
        "\n",
        "    model = Model(inputs=[inputs, masks], outputs=output)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss=CategoricalCrossentropy(),\n",
        "                  metrics=CategoricalAccuracy())\n",
        "    return model\n",
        "\n",
        "roberta_model = TFRobertaModel.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "tokenizer_roberta = RobertaTokenizerFast.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "model1 = create_model(roberta_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP0HKeoUVtCI",
        "outputId": "ee114835-dc3e-4886-8594-bc440e1d89a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion were not used when initializing TFRobertaModel: ['classifier']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.load_weights(\"textmodelweights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "mvqeI9ILEtI4",
        "outputId": "a118a158-e3aa-4e0f-85c4-d227950d63a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ebf66afc8e06>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textmodelweights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 51380224, sblock->base_addr = 0, stored_eof = 499291552)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "# Create an augmentation pipeline\n",
        "augmenter = naw.SynonymAug(aug_src='wordnet')\n",
        "sentdict = {'IEO':\"It's eleven o'clock\",'TIE':\"That is exactly what happened\",'IOM':\"I'm on my way to the meeting\",'IWW':\"I wonder what this is about\",'TAI':\"The airplane is almost full\",'MTI':\"Maybe tomorrow it will be cold\",\n",
        "            'IWL':\"I would like a new alarm clock\",'ITH':\"I think I have a doctor's appointment\",'DFA':\"Don't forget a jacket\",'ITS':\"I think I've seen this before\",'TSI':\"The surface is slick\",'WSI':\"We'll stop in a couple of minutes\"}\n",
        "testsentences = []\n",
        "finalemotion=[]\n",
        "def create(sentence):\n",
        "  text = sentence + ' 😠'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(0)\n",
        "  finalemotion.append(0)\n",
        "  finalemotion.append(0)\n",
        "  text = sentence + ' 😖'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(1)\n",
        "  finalemotion.append(1)\n",
        "  finalemotion.append(1)\n",
        "  text = sentence + ' 😱'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(2)\n",
        "  finalemotion.append(2)\n",
        "  finalemotion.append(2)\n",
        "  text = sentence + ' 😊'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(3)\n",
        "  finalemotion.append(3)\n",
        "  finalemotion.append(3)\n",
        "  text = sentence + ' 😐'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(4)\n",
        "  finalemotion.append(4)\n",
        "  finalemotion.append(4)\n",
        "  text = sentence + ' 😢'\n",
        "  augmented_text1 = augmenter.augment(text)\n",
        "  augmented_text2 = augmenter.augment(text)\n",
        "  testsentences.append(text)\n",
        "  testsentences.append(augmented_text1[0])\n",
        "  testsentences.append(augmented_text2[0])\n",
        "  finalemotion.append(5)\n",
        "  finalemotion.append(5)\n",
        "  finalemotion.append(5)\n",
        "for k in sentdict.keys():\n",
        "  create(sentdict[k])\n",
        "\n",
        "import re\n",
        "import random\n",
        "\n",
        "augmentedemojitext=[]\n",
        "emotions=[]\n",
        "\n",
        "def emoji_augmentation(text):\n",
        "    # Define a dictionary of emoji replacements\n",
        "    emoji_replacements = {\n",
        "        \"😠\": [\"😠\", \"😡\", \"😤\", \"😾\"],\n",
        "        \"😖\": [\"😖\", \"😣\", \"😞\", \"😷\"],\n",
        "        \"😱\": [\"😱\", \"😨\", \"😰\", \"😲\"],\n",
        "        \"😊\": [\"😊\", \"😄\", \"😁\", \"😆\"],\n",
        "        \"😐\": [\"😐\", \"😑\", \"😶\", \"😏\"],\n",
        "        \"😢\": [\"😢\", \"😭\", \"😓\", \"😥\"],\n",
        "        # Add more emojis and their possible replacements\n",
        "    }\n",
        "\n",
        "    emoji_dict = {\"😠\":0,\"😖\": 1,\"😱\": 2,\"😊\": 3,\"😐\": 4,\"😢\": 5}\n",
        "\n",
        "    # Use regular expression to find emojis in the text\n",
        "    emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]+')\n",
        "    matches = emoji_pattern.findall(text)\n",
        "\n",
        "    # Perform augmentation by randomly replacing emojis\n",
        "    for match in matches:\n",
        "      if match in emoji_replacements:\n",
        "        for replacement in emoji_replacements[match]:\n",
        "          augmented_text = text\n",
        "          augmented_text = augmented_text.replace(match, replacement)\n",
        "          augmentedemojitext.append(augmented_text)\n",
        "          emotions.append(emoji_dict[match])\n",
        "\n",
        "for text in testsentences:\n",
        "  emoji_augmentation(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfxK0Mm-KzkN",
        "outputId": "50142e57-4528-4884-8c71-cce2e0d23616"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tabulate import tabulate\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(augmentedemojitext,emotions, test_size=0.1, random_state=42)\n",
        "\n",
        "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.optimizers import Adam\n",
        "tokenizer_roberta = RobertaTokenizerFast.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "\n",
        "MAX_LEN=128\n",
        "\n",
        "def tokenize_roberta(data, max_len=MAX_LEN) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer_roberta.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids),np.array(attention_masks)\n",
        "\n",
        "def create_model(bert_model, max_len=MAX_LEN):\n",
        "    inputs = Input(shape=(max_len,), dtype='int32')\n",
        "    masks = Input(shape=(max_len,), dtype='int32')\n",
        "\n",
        "    bert_output = bert_model([inputs, masks])[1]\n",
        "\n",
        "    dense_1 = Dense(128, activation='relu')(bert_output)\n",
        "    dropout_1 = Dropout(0.5)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(64, activation='relu')(dropout_1)\n",
        "    dropout_2 = Dropout(0.5)(dense_2)\n",
        "\n",
        "    output = Dense(6, activation='softmax')(dropout_2)\n",
        "\n",
        "    model = Model(inputs=[inputs, masks], outputs=output)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss=CategoricalCrossentropy(),\n",
        "                  metrics=CategoricalAccuracy())\n",
        "    return model\n",
        "\n",
        "roberta_model = TFRobertaModel.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
        "model = create_model(roberta_model, MAX_LEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288,
          "referenced_widgets": [
            "931d6563bad54573bc9e2ba2c734e2d7",
            "2c105bce765748a88128076f76ec1b1f",
            "86e8a2915bd94a63ac980fe31b2c68c3",
            "6f8b431e5e9b4651b153de438c142055",
            "5bd23b6016684e3c869e9228fb52e0fe",
            "04a2b5ab0240462fbe51676b8b7ed478",
            "4809baa688044b398c9ff7100f4db297",
            "0ea14b8deb56482ab7b115e4f25c8c8c",
            "671f2aa2b3904886a6daecd69497e763",
            "bbcf0932d99f4a58be7db5449fa00d58",
            "110cae555cfb4c06b5e048eac8f6a4d0",
            "306e9042f70d4409a816523dc9cb8661",
            "f1255a4c72d643d2a46e6c137850fe1f",
            "1995644087a343008fb38a11295e4a80",
            "70a34d5b89934c768900bb9180472e8c",
            "269452853b874f02af94c9f16c0733dc",
            "c6f69f51e4a64dd1a4fbb8387f9d7ebc",
            "3c518d0f5d1d4fdfa3f547506316da07",
            "0f0c4279ec0842639e00bb7330539815",
            "397d06db4f114dc8ba311c318bd0e2a7",
            "8095603c43ff4c1994d6da615a747b72",
            "4918c5f2fb804a5b97d563c2eb8d8892",
            "d0194e32012d49b8aa85055be40fd962",
            "4225110c8216465c9cc821890dbdf305",
            "1f4f872e7a344712b28116efc045976e",
            "e470003c34f14555a1c6e17797c11459",
            "ca792b608998452c8a8f65d50075bb2f",
            "f7b38b39695a4f8ca91c25dd6782c97e",
            "af2347616de74b15827664dd5525f13d",
            "7c18b11ea6d44a74a747689f87593395",
            "92c4e159c26f49d1b3bb8d758b747c82",
            "1dc02df563a344aba34d4321426a91e6",
            "4ef1c1e86ecc4ca8a7520192a7ef6098",
            "5a3b15f9bafc4b899e8aee0bffc54285",
            "faa44895f9464cb8b1a491f2f3b7d610",
            "2ad2f51c82e6453dbfb5bda9b9d4d494",
            "47e5d511d06c417aa486d3359dd6327d",
            "2f90d9eb7d1f447fb35b7700ecb0a515",
            "d17b381e13f8467fae86ccb723a1c243",
            "180c79e05dd5476585352cdce62c22bf",
            "81c9596824474a3884c87bcca6750332",
            "f433b1481af24ae99f7bac5af65ecaef",
            "8bacdf15feaa4c72bd04da2c1d324738",
            "472e16caf5f84060a19be7bef1fd3e0c",
            "60339f04a0f3439986c5e800ff169ada",
            "2bbd0c2b87704468b0abf99b58ce0ea1",
            "c900e7edb64049f694f138f438fba18d",
            "b89de17dad75432d97f6671b35052948",
            "56b14535aabe41e1a6204f6d2896f5f5",
            "a566520ccade4596a2de23d628689e5b",
            "020a957349cb48ee8f1aa38860ab9fdc",
            "732a8ac4f9004526ba7434afcece1663",
            "8da2db33e9ac48a489f00e84a79a874b",
            "05148b42492642d99b455e184d7b0410",
            "84c66754db5f42ada803d1e3c3e3da98"
          ]
        },
        "id": "ER6ZgZXCK_2k",
        "outputId": "ee5836c8-5f02-4a62-9ea9-cdea252ec09f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931d6563bad54573bc9e2ba2c734e2d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "306e9042f70d4409a816523dc9cb8661"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0194e32012d49b8aa85055be40fd962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a3b15f9bafc4b899e8aee0bffc54285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60339f04a0f3439986c5e800ff169ada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion were not used when initializing TFRobertaModel: ['classifier']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_masks = tokenize_roberta(X_train1, MAX_LEN)#tokenize_roberta(X_train, MAX_LEN)\n",
        "history = model.fit([train_inputs, train_masks],  OneHotEncoder().fit_transform(np.array(y_train1).reshape(-1, 1)).toarray(),  epochs=4,  batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS7cExguLGVI",
        "outputId": "54b65a4a-e216-4ff4-a5b2-cb394974e177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "25/25 [==============================] - 94s 732ms/step - loss: 1.7428 - categorical_accuracy: 0.2420\n",
            "Epoch 2/4\n",
            "25/25 [==============================] - 18s 724ms/step - loss: 1.4681 - categorical_accuracy: 0.4041\n",
            "Epoch 3/4\n",
            "25/25 [==============================] - 18s 736ms/step - loss: 1.1800 - categorical_accuracy: 0.5534\n",
            "Epoch 4/4\n",
            "25/25 [==============================] - 19s 779ms/step - loss: 0.9394 - categorical_accuracy: 0.6448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "textemo=[]\n",
        "for s in X_test1:\n",
        "  textemo.append(np.argmax(model.predict([tokenize_roberta([s])])[0]))"
      ],
      "metadata": {
        "id": "jlWCvgpXLI36"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te=0\n",
        "for i in range(0,len(X_test1)):\n",
        "  if y_test1[i] == textemo[i]:\n",
        "    te= te+1\n",
        "print(te/len(X_test1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1sFtk6-LKSL",
        "outputId": "67ec1e15-441b-40f7-9f5b-ce109ec823e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7701149425287356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "Audio_model = load_model(\"/content/emotion_classification_Audio_model_With_Augmentation.h5\")\n",
        "Video_model = load_model(\"/content/drive/MyDrive/emotion_classification_Video_model.h5\")\n",
        "text_model = model"
      ],
      "metadata": {
        "id": "vL3_xK8STdRF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "AudiosData = []\n",
        "data_path = '/content/Audio/AudioWAV'\n",
        "for folder in os.listdir(data_path):\n",
        "    file_path = os.path.join(data_path, folder)\n",
        "    AudiosData.append(folder)\n",
        "\n",
        "print(len(AudiosData))\n",
        "\n",
        "ad, AudiosDataTest = train_test_split(AudiosData, test_size=0.3, random_state=42)\n",
        "testdata=[]\n",
        "for data in AudiosDataTest:\n",
        "  testdata.append(data[:-3])\n",
        "\n",
        "finalemotion = []\n",
        "for file in testdata:\n",
        "  if 'ANG' in file:\n",
        "    finalemotion.append(0)\n",
        "  elif 'DIS' in file:\n",
        "    finalemotion.append(1)\n",
        "  elif 'FEA' in file:\n",
        "    finalemotion.append(2)\n",
        "  elif 'HAP' in file:\n",
        "    finalemotion.append(3)\n",
        "  elif 'NEU' in file:\n",
        "    finalemotion.append(4)\n",
        "  elif 'SAD' in file:\n",
        "    finalemotion.append(5)\n",
        "\n",
        "emoji_replacements = {\n",
        "        \"😠\": [\"😠\", \"😡\", \"😤\", \"😾\"],\n",
        "        \"😖\": [\"😖\", \"😣\", \"😞\", \"😷\"],\n",
        "        \"😱\": [\"😱\", \"😨\", \"😰\", \"😲\"],\n",
        "        \"😊\": [\"😊\", \"😄\", \"😁\", \"😆\"],\n",
        "        \"😐\": [\"😐\", \"😑\", \"😶\", \"😏\"],\n",
        "        \"😢\": [\"😢\", \"😭\", \"😓\", \"😥\"],\n",
        "        # Add more emojis and their possible replacements\n",
        "    }\n",
        "def CreateSentences(file,sentence,testsentences):\n",
        "  if 'ANG' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😠']))\n",
        "  elif 'DIS' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😖']))\n",
        "  elif 'FEA' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😱']))\n",
        "  elif 'HAP' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😊']))\n",
        "  elif 'NEU' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😐']))\n",
        "  elif 'SAD' in file:\n",
        "    testsentences.append(sentence + random.choice(emoji_replacements['😢']))\n",
        "\n",
        "testsentences=[]\n",
        "sentdict = {'IEO':\"It's eleven o'clock\",'TIE':\"That is exactly what happened\",'IOM':\"I'm on my way to the meeting\",'IWW':\"I wonder what this is about\",'TAI':\"The airplane is almost full\",'MTI':\"Maybe tomorrow it will be cold\",\n",
        "            'IWL':\"I would like a new alarm clock\",'ITH':\"I think I have a doctor's appointment\",'DFA':\"Don't forget a jacket\",'ITS':\"I think I've seen this before\",'TSI':\"The surface is slick\",'WSI':\"We'll stop in a couple of minutes\"}\n",
        "for file in testdata :\n",
        "  CreateSentences(file,sentdict[file[5:8]],testsentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBWk3Sc3LNTc",
        "outputId": "e5a10ce2-70d0-4b11-a14a-1cd5c666b07f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testsentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8_TzaSrDuS4",
        "outputId": "f7cb194c-abee-499b-b740-a00b619da322"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I wonder what this is about😠',\n",
              " \"Don't forget a jacket😨\",\n",
              " \"I think I've seen this before😶\",\n",
              " \"Don't forget a jacket😱\",\n",
              " 'The surface is slick😑',\n",
              " 'Maybe tomorrow it will be cold😤',\n",
              " 'The airplane is almost full😣',\n",
              " \"Don't forget a jacket😲\",\n",
              " \"It's eleven o'clock😢\",\n",
              " \"I'm on my way to the meeting😾\",\n",
              " \"I think I've seen this before😭\",\n",
              " \"I'm on my way to the meeting😆\",\n",
              " 'The airplane is almost full😑',\n",
              " 'I would like a new alarm clock😑',\n",
              " 'I would like a new alarm clock😞',\n",
              " 'I would like a new alarm clock😣',\n",
              " \"Don't forget a jacket😡\",\n",
              " \"It's eleven o'clock😣\",\n",
              " \"It's eleven o'clock😞\",\n",
              " \"Don't forget a jacket😶\",\n",
              " \"Don't forget a jacket😡\",\n",
              " \"It's eleven o'clock😷\",\n",
              " \"Don't forget a jacket😑\",\n",
              " \"It's eleven o'clock😣\",\n",
              " \"It's eleven o'clock😁\",\n",
              " \"It's eleven o'clock😓\",\n",
              " \"I think I've seen this before😥\",\n",
              " 'The airplane is almost full😱',\n",
              " \"I think I have a doctor's appointment😨\",\n",
              " 'That is exactly what happened😣',\n",
              " \"It's eleven o'clock😰\",\n",
              " 'Maybe tomorrow it will be cold😾',\n",
              " 'Maybe tomorrow it will be cold😄',\n",
              " 'Maybe tomorrow it will be cold😶',\n",
              " 'I wonder what this is about😏',\n",
              " 'That is exactly what happened😤',\n",
              " 'I wonder what this is about😄',\n",
              " \"We'll stop in a couple of minutes😏\",\n",
              " \"I think I have a doctor's appointment😆\",\n",
              " 'That is exactly what happened😞',\n",
              " 'I wonder what this is about😑',\n",
              " \"It's eleven o'clock😭\",\n",
              " \"It's eleven o'clock😥\",\n",
              " \"I'm on my way to the meeting😢\",\n",
              " \"I think I've seen this before😊\",\n",
              " \"I think I've seen this before😐\",\n",
              " 'That is exactly what happened😣',\n",
              " 'The surface is slick😠',\n",
              " \"It's eleven o'clock😱\",\n",
              " 'The airplane is almost full😄',\n",
              " \"It's eleven o'clock😁\",\n",
              " \"Don't forget a jacket😭\",\n",
              " 'I would like a new alarm clock😰',\n",
              " \"I'm on my way to the meeting😾\",\n",
              " 'I wonder what this is about😣',\n",
              " \"It's eleven o'clock😞\",\n",
              " \"I think I have a doctor's appointment😥\",\n",
              " \"Don't forget a jacket😞\",\n",
              " \"It's eleven o'clock😖\",\n",
              " 'That is exactly what happened😏',\n",
              " \"We'll stop in a couple of minutes😶\",\n",
              " 'That is exactly what happened😑',\n",
              " \"Don't forget a jacket😁\",\n",
              " 'Maybe tomorrow it will be cold😆',\n",
              " 'The airplane is almost full😆',\n",
              " 'I would like a new alarm clock😐',\n",
              " 'Maybe tomorrow it will be cold😏',\n",
              " 'That is exactly what happened😠',\n",
              " \"I think I've seen this before😣\",\n",
              " \"I'm on my way to the meeting😑\",\n",
              " \"It's eleven o'clock😖\",\n",
              " \"It's eleven o'clock😲\",\n",
              " \"I'm on my way to the meeting😤\",\n",
              " 'I would like a new alarm clock😭',\n",
              " 'I would like a new alarm clock😏',\n",
              " \"Don't forget a jacket😤\",\n",
              " 'Maybe tomorrow it will be cold😄',\n",
              " \"It's eleven o'clock😠\",\n",
              " \"I think I've seen this before😓\",\n",
              " 'The surface is slick😷',\n",
              " 'The surface is slick😢',\n",
              " \"I'm on my way to the meeting😥\",\n",
              " 'The airplane is almost full😠',\n",
              " \"I think I have a doctor's appointment😰\",\n",
              " \"I'm on my way to the meeting😰\",\n",
              " 'I would like a new alarm clock😓',\n",
              " 'I wonder what this is about😱',\n",
              " 'That is exactly what happened😱',\n",
              " 'I would like a new alarm clock😠',\n",
              " \"It's eleven o'clock😢\",\n",
              " 'Maybe tomorrow it will be cold😤',\n",
              " 'I would like a new alarm clock😤',\n",
              " 'The airplane is almost full😊',\n",
              " \"I think I have a doctor's appointment😊\",\n",
              " \"Don't forget a jacket😏\",\n",
              " 'The airplane is almost full😁',\n",
              " 'I wonder what this is about😄',\n",
              " 'I would like a new alarm clock😣',\n",
              " 'I wonder what this is about😣',\n",
              " \"It's eleven o'clock😾\",\n",
              " 'Maybe tomorrow it will be cold😥',\n",
              " 'Maybe tomorrow it will be cold😓',\n",
              " 'I would like a new alarm clock😲',\n",
              " 'Maybe tomorrow it will be cold😁',\n",
              " \"I'm on my way to the meeting😰\",\n",
              " \"I think I have a doctor's appointment😾\",\n",
              " 'Maybe tomorrow it will be cold😆',\n",
              " \"It's eleven o'clock😄\",\n",
              " \"It's eleven o'clock😥\",\n",
              " \"I think I've seen this before😄\",\n",
              " \"I think I've seen this before😲\",\n",
              " \"Don't forget a jacket😑\",\n",
              " 'I would like a new alarm clock😲',\n",
              " 'I wonder what this is about😐',\n",
              " 'Maybe tomorrow it will be cold😤',\n",
              " 'Maybe tomorrow it will be cold😲',\n",
              " \"We'll stop in a couple of minutes😠\",\n",
              " \"I think I've seen this before😡\",\n",
              " 'That is exactly what happened😐',\n",
              " \"I think I have a doctor's appointment😏\",\n",
              " 'Maybe tomorrow it will be cold😏',\n",
              " \"Don't forget a jacket😤\",\n",
              " 'I wonder what this is about😞',\n",
              " \"We'll stop in a couple of minutes😷\",\n",
              " 'Maybe tomorrow it will be cold😐',\n",
              " \"It's eleven o'clock😥\",\n",
              " \"Don't forget a jacket😁\",\n",
              " 'I wonder what this is about😁',\n",
              " \"I think I have a doctor's appointment😐\",\n",
              " \"We'll stop in a couple of minutes😣\",\n",
              " 'Maybe tomorrow it will be cold😲',\n",
              " 'Maybe tomorrow it will be cold😁',\n",
              " 'That is exactly what happened😓',\n",
              " \"I think I have a doctor's appointment😤\",\n",
              " 'The airplane is almost full😨',\n",
              " 'Maybe tomorrow it will be cold😾',\n",
              " \"It's eleven o'clock😾\",\n",
              " 'I would like a new alarm clock😭',\n",
              " \"Don't forget a jacket😏\",\n",
              " \"It's eleven o'clock😢\",\n",
              " \"It's eleven o'clock😢\",\n",
              " 'The surface is slick😢',\n",
              " \"I think I've seen this before😄\",\n",
              " \"We'll stop in a couple of minutes😭\",\n",
              " \"We'll stop in a couple of minutes😊\",\n",
              " \"I think I have a doctor's appointment😐\",\n",
              " \"I think I've seen this before😆\",\n",
              " 'The airplane is almost full😢',\n",
              " \"I think I have a doctor's appointment😐\",\n",
              " 'I would like a new alarm clock😞',\n",
              " 'I wonder what this is about😾',\n",
              " \"I think I have a doctor's appointment😭\",\n",
              " 'The surface is slick😆',\n",
              " 'The airplane is almost full😠',\n",
              " 'I would like a new alarm clock😨',\n",
              " 'Maybe tomorrow it will be cold😞',\n",
              " \"It's eleven o'clock😠\",\n",
              " 'The airplane is almost full😤',\n",
              " 'The airplane is almost full😾',\n",
              " \"I think I have a doctor's appointment😤\",\n",
              " 'I would like a new alarm clock😱',\n",
              " 'That is exactly what happened😑',\n",
              " \"I think I have a doctor's appointment😶\",\n",
              " 'The surface is slick😐',\n",
              " \"It's eleven o'clock😑\",\n",
              " 'I would like a new alarm clock😲',\n",
              " 'The surface is slick😠',\n",
              " \"I'm on my way to the meeting😱\",\n",
              " 'I would like a new alarm clock😲',\n",
              " \"I think I've seen this before😲\",\n",
              " \"I think I've seen this before😷\",\n",
              " \"It's eleven o'clock😨\",\n",
              " 'Maybe tomorrow it will be cold😣',\n",
              " 'I would like a new alarm clock😣',\n",
              " \"Don't forget a jacket😰\",\n",
              " \"I think I've seen this before😁\",\n",
              " 'I would like a new alarm clock😓',\n",
              " 'That is exactly what happened😞',\n",
              " \"It's eleven o'clock😆\",\n",
              " \"I think I have a doctor's appointment😏\",\n",
              " \"We'll stop in a couple of minutes😨\",\n",
              " \"It's eleven o'clock😱\",\n",
              " \"I'm on my way to the meeting😠\",\n",
              " \"It's eleven o'clock😰\",\n",
              " \"I think I have a doctor's appointment😠\",\n",
              " \"I'm on my way to the meeting😏\",\n",
              " \"I think I have a doctor's appointment😨\",\n",
              " \"I think I've seen this before😁\",\n",
              " \"It's eleven o'clock😞\",\n",
              " 'The airplane is almost full😲',\n",
              " 'I would like a new alarm clock😊',\n",
              " \"I'm on my way to the meeting😁\",\n",
              " \"I think I've seen this before😣\",\n",
              " \"I think I've seen this before😥\",\n",
              " \"It's eleven o'clock😄\",\n",
              " 'That is exactly what happened😆',\n",
              " 'That is exactly what happened😏',\n",
              " \"Don't forget a jacket😨\",\n",
              " \"I think I've seen this before😄\",\n",
              " 'The airplane is almost full😷',\n",
              " \"I think I've seen this before😏\",\n",
              " 'The surface is slick😨',\n",
              " \"We'll stop in a couple of minutes😁\",\n",
              " \"It's eleven o'clock😞\",\n",
              " 'That is exactly what happened😐',\n",
              " 'That is exactly what happened😏',\n",
              " \"We'll stop in a couple of minutes😶\",\n",
              " 'I would like a new alarm clock😞',\n",
              " 'I would like a new alarm clock😆',\n",
              " 'I would like a new alarm clock😾',\n",
              " 'Maybe tomorrow it will be cold😄',\n",
              " 'That is exactly what happened😲',\n",
              " 'The surface is slick😭',\n",
              " 'I would like a new alarm clock😐',\n",
              " \"I'm on my way to the meeting😁\",\n",
              " 'I wonder what this is about😁',\n",
              " 'The surface is slick😢',\n",
              " \"It's eleven o'clock😊\",\n",
              " \"Don't forget a jacket😐\",\n",
              " 'The surface is slick😞',\n",
              " 'I would like a new alarm clock😁',\n",
              " \"Don't forget a jacket😱\",\n",
              " \"It's eleven o'clock😊\",\n",
              " \"It's eleven o'clock😷\",\n",
              " \"Don't forget a jacket😲\",\n",
              " \"I think I have a doctor's appointment😏\",\n",
              " 'That is exactly what happened😨',\n",
              " \"I'm on my way to the meeting😷\",\n",
              " \"It's eleven o'clock😰\",\n",
              " \"I think I have a doctor's appointment😡\",\n",
              " \"Don't forget a jacket😤\",\n",
              " \"I'm on my way to the meeting😰\",\n",
              " 'Maybe tomorrow it will be cold😡',\n",
              " \"I think I've seen this before😄\",\n",
              " \"It's eleven o'clock😰\",\n",
              " \"I think I've seen this before😾\",\n",
              " \"Don't forget a jacket😄\",\n",
              " \"It's eleven o'clock😆\",\n",
              " \"It's eleven o'clock😾\",\n",
              " \"I think I've seen this before😾\",\n",
              " \"I'm on my way to the meeting😊\",\n",
              " 'The surface is slick😢',\n",
              " \"I think I've seen this before😆\",\n",
              " 'I would like a new alarm clock😾',\n",
              " 'I wonder what this is about😊',\n",
              " \"I'm on my way to the meeting😏\",\n",
              " \"We'll stop in a couple of minutes😡\",\n",
              " 'Maybe tomorrow it will be cold😥',\n",
              " \"I'm on my way to the meeting😡\",\n",
              " 'The airplane is almost full😭',\n",
              " 'The airplane is almost full😖',\n",
              " \"I think I've seen this before😞\",\n",
              " \"It's eleven o'clock😤\",\n",
              " 'I wonder what this is about😾',\n",
              " \"I think I've seen this before😊\",\n",
              " \"We'll stop in a couple of minutes😭\",\n",
              " 'That is exactly what happened😭',\n",
              " 'That is exactly what happened😣',\n",
              " 'That is exactly what happened😭',\n",
              " \"We'll stop in a couple of minutes😏\",\n",
              " \"Don't forget a jacket😾\",\n",
              " \"I think I've seen this before😓\",\n",
              " 'The surface is slick😠',\n",
              " \"It's eleven o'clock😊\",\n",
              " \"I think I have a doctor's appointment😏\",\n",
              " \"I think I've seen this before😾\",\n",
              " \"I think I have a doctor's appointment😾\",\n",
              " \"It's eleven o'clock😱\",\n",
              " \"I think I've seen this before😱\",\n",
              " 'Maybe tomorrow it will be cold😄',\n",
              " 'That is exactly what happened😰',\n",
              " 'The airplane is almost full😢',\n",
              " 'The surface is slick😷',\n",
              " 'The airplane is almost full😊',\n",
              " 'I wonder what this is about😊',\n",
              " \"I think I've seen this before😶\",\n",
              " \"We'll stop in a couple of minutes😐\",\n",
              " \"It's eleven o'clock😥\",\n",
              " 'The surface is slick😡',\n",
              " \"We'll stop in a couple of minutes😨\",\n",
              " 'I would like a new alarm clock😑',\n",
              " \"Don't forget a jacket😆\",\n",
              " \"I think I've seen this before😊\",\n",
              " \"It's eleven o'clock😤\",\n",
              " \"Don't forget a jacket😓\",\n",
              " \"I think I have a doctor's appointment😞\",\n",
              " 'I wonder what this is about😷',\n",
              " 'I wonder what this is about😆',\n",
              " \"It's eleven o'clock😷\",\n",
              " 'I would like a new alarm clock😷',\n",
              " \"It's eleven o'clock😑\",\n",
              " 'Maybe tomorrow it will be cold😢',\n",
              " \"I'm on my way to the meeting😾\",\n",
              " \"We'll stop in a couple of minutes😣\",\n",
              " \"Don't forget a jacket😓\",\n",
              " \"Don't forget a jacket😖\",\n",
              " \"It's eleven o'clock😢\",\n",
              " \"I'm on my way to the meeting😓\",\n",
              " \"It's eleven o'clock😷\",\n",
              " \"It's eleven o'clock😁\",\n",
              " 'I would like a new alarm clock😑',\n",
              " 'The surface is slick😣',\n",
              " \"I'm on my way to the meeting😤\",\n",
              " \"We'll stop in a couple of minutes😾\",\n",
              " \"It's eleven o'clock😞\",\n",
              " 'That is exactly what happened😏',\n",
              " \"It's eleven o'clock😖\",\n",
              " \"We'll stop in a couple of minutes😑\",\n",
              " \"It's eleven o'clock😷\",\n",
              " 'I would like a new alarm clock😲',\n",
              " 'The airplane is almost full😆',\n",
              " \"It's eleven o'clock😥\",\n",
              " 'I would like a new alarm clock😄',\n",
              " \"It's eleven o'clock😡\",\n",
              " 'That is exactly what happened😢',\n",
              " \"It's eleven o'clock😤\",\n",
              " \"Don't forget a jacket😤\",\n",
              " 'That is exactly what happened😱',\n",
              " \"I think I've seen this before😏\",\n",
              " 'The surface is slick😆',\n",
              " \"We'll stop in a couple of minutes😱\",\n",
              " \"I'm on my way to the meeting😭\",\n",
              " \"It's eleven o'clock😁\",\n",
              " 'I would like a new alarm clock😾',\n",
              " \"I'm on my way to the meeting😤\",\n",
              " 'The airplane is almost full😾',\n",
              " 'I would like a new alarm clock😥',\n",
              " \"We'll stop in a couple of minutes😄\",\n",
              " 'The airplane is almost full😥',\n",
              " 'The surface is slick😲',\n",
              " \"It's eleven o'clock😞\",\n",
              " \"I think I have a doctor's appointment😄\",\n",
              " 'I would like a new alarm clock😭',\n",
              " 'I would like a new alarm clock😶',\n",
              " 'The surface is slick😁',\n",
              " \"I'm on my way to the meeting😰\",\n",
              " \"It's eleven o'clock😾\",\n",
              " 'Maybe tomorrow it will be cold😄',\n",
              " \"It's eleven o'clock😄\",\n",
              " 'The airplane is almost full😓',\n",
              " \"It's eleven o'clock😡\",\n",
              " \"I'm on my way to the meeting😤\",\n",
              " 'I would like a new alarm clock😾',\n",
              " \"I think I've seen this before😏\",\n",
              " \"I think I have a doctor's appointment😆\",\n",
              " \"We'll stop in a couple of minutes😏\",\n",
              " 'I wonder what this is about😐',\n",
              " \"I'm on my way to the meeting😠\",\n",
              " 'I would like a new alarm clock😡',\n",
              " 'I would like a new alarm clock😆',\n",
              " 'The airplane is almost full😣',\n",
              " 'The airplane is almost full😲',\n",
              " \"I'm on my way to the meeting😭\",\n",
              " \"It's eleven o'clock😣\",\n",
              " 'I would like a new alarm clock😰',\n",
              " \"It's eleven o'clock😱\",\n",
              " 'That is exactly what happened😣',\n",
              " 'I would like a new alarm clock😊',\n",
              " 'I would like a new alarm clock😱',\n",
              " 'The surface is slick😊',\n",
              " \"Don't forget a jacket😆\",\n",
              " \"I think I've seen this before😥\",\n",
              " \"It's eleven o'clock😁\",\n",
              " \"I'm on my way to the meeting😭\",\n",
              " \"It's eleven o'clock😓\",\n",
              " \"I think I have a doctor's appointment😡\",\n",
              " 'I wonder what this is about😥',\n",
              " \"We'll stop in a couple of minutes😖\",\n",
              " 'The airplane is almost full😑',\n",
              " 'Maybe tomorrow it will be cold😢',\n",
              " 'The surface is slick😣',\n",
              " \"It's eleven o'clock😣\",\n",
              " 'The surface is slick😱',\n",
              " 'The surface is slick😄',\n",
              " \"Don't forget a jacket😖\",\n",
              " 'I wonder what this is about😓',\n",
              " \"It's eleven o'clock😓\",\n",
              " 'I would like a new alarm clock😖',\n",
              " \"Don't forget a jacket😷\",\n",
              " \"It's eleven o'clock😓\",\n",
              " 'I would like a new alarm clock😰',\n",
              " \"Don't forget a jacket😖\",\n",
              " 'That is exactly what happened😠',\n",
              " \"I'm on my way to the meeting😑\",\n",
              " \"It's eleven o'clock😣\",\n",
              " \"It's eleven o'clock😷\",\n",
              " \"I think I've seen this before😭\",\n",
              " \"I think I've seen this before😨\",\n",
              " \"I think I have a doctor's appointment😨\",\n",
              " \"It's eleven o'clock😆\",\n",
              " \"It's eleven o'clock😠\",\n",
              " 'That is exactly what happened😊',\n",
              " \"It's eleven o'clock😞\",\n",
              " \"I'm on my way to the meeting😭\",\n",
              " 'The airplane is almost full😨',\n",
              " \"I'm on my way to the meeting😖\",\n",
              " \"I'm on my way to the meeting😣\",\n",
              " \"I think I've seen this before😊\",\n",
              " 'I would like a new alarm clock😱',\n",
              " 'Maybe tomorrow it will be cold😨',\n",
              " \"We'll stop in a couple of minutes😾\",\n",
              " \"I'm on my way to the meeting😭\",\n",
              " \"It's eleven o'clock😾\",\n",
              " 'I would like a new alarm clock😄',\n",
              " 'Maybe tomorrow it will be cold😥',\n",
              " \"It's eleven o'clock😞\",\n",
              " 'Maybe tomorrow it will be cold😥',\n",
              " \"I think I've seen this before😷\",\n",
              " \"I think I have a doctor's appointment😲\",\n",
              " 'I wonder what this is about😄',\n",
              " \"We'll stop in a couple of minutes😄\",\n",
              " \"I'm on my way to the meeting😲\",\n",
              " \"It's eleven o'clock😊\",\n",
              " 'Maybe tomorrow it will be cold😣',\n",
              " \"It's eleven o'clock😊\",\n",
              " 'Maybe tomorrow it will be cold😲',\n",
              " 'Maybe tomorrow it will be cold😷',\n",
              " \"I'm on my way to the meeting😰\",\n",
              " 'Maybe tomorrow it will be cold😲',\n",
              " 'I would like a new alarm clock😏',\n",
              " 'I wonder what this is about😖',\n",
              " \"I think I have a doctor's appointment😐\",\n",
              " \"We'll stop in a couple of minutes😶\",\n",
              " \"Don't forget a jacket😁\",\n",
              " \"It's eleven o'clock😱\",\n",
              " 'The airplane is almost full😄',\n",
              " \"It's eleven o'clock😢\",\n",
              " 'Maybe tomorrow it will be cold😥',\n",
              " 'That is exactly what happened😏',\n",
              " 'The surface is slick😠',\n",
              " 'I would like a new alarm clock😠',\n",
              " \"We'll stop in a couple of minutes😶\",\n",
              " 'The surface is slick😶']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "td = testdata\n",
        "testdata = td[:1800]\n",
        "print(len(testdata))\n",
        "print(len(td))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQtcIQmSMZ1-",
        "outputId": "bf71f21c-3c65-46a1-a4b3-8926dbf0d43a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1800\n",
            "2233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = td[1800:]\n",
        "testsentences = testsentences[1800:]\n",
        "finalemotion = finalemotion[1800:]"
      ],
      "metadata": {
        "id": "TipV_NtN6Cm3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import librosa\n",
        "\n",
        "# Function to extract features from video\n",
        "def extract_video_features(video_path):\n",
        "    # Your video feature extraction code here\n",
        "    # Example: Using OpenCV to extract color histogram features\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed_frame = cv2.resize(frame, (224, 224))\n",
        "        processed_frame = processed_frame / 255.0  # Normalize pixel values\n",
        "\n",
        "    cap.release()\n",
        "    return processed_frame\n",
        "\n",
        "# Function to extract features from audio\n",
        "def extract_audio_features(file_path, mfcc=True, chroma=True, mel=True):\n",
        "    # Your audio feature extraction code here\n",
        "    # Example: Using librosa to extract MFCC features\n",
        "    audio, sample_rate = librosa.load(file_path)\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    #if chroma:\n",
        "    #    chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate), axis=1)\n",
        "    #    result = np.hstack((result, chroma))\n",
        "    #if mel:\n",
        "    #    mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate), axis=1)\n",
        "    #    result = np.hstack((result, mel))\n",
        "    return result\n",
        "\n",
        "# Load your pre-trained text model (replace with your actual model loading code)\n",
        "def predict_text_emotion(text):\n",
        "    # Your text prediction code here\n",
        "    # Example: Using a simple RandomForestClassifier\n",
        "    # You should replace this with your actual text classification model\n",
        "    return text_model.predict([tokenize_roberta([text])])[0]\n",
        "\n",
        "# Load your pre-trained video model (replace with your actual model loading code)\n",
        "def predict_video_emotion(video_path):\n",
        "    # Your video prediction code here\n",
        "    # Example: Extract video features and use a simple RandomForestClassifier\n",
        "    video_features = extract_video_features(video_path)\n",
        "    return Video_model.predict(np.array([video_features]))\n",
        "\n",
        "# Load your pre-trained audio model (replace with your actual model loading code)\n",
        "def predict_audio_emotion(audio_path):\n",
        "    # Your audio prediction code here\n",
        "    # Example: Extract audio features and use a simple RandomForestClassifier\n",
        "    audio_features = extract_audio_features(audio_path)\n",
        "    return Audio_model.predict(np.array([audio_features]))\n",
        "\n",
        "textemotion_pred=[]\n",
        "videoemotion_pred=[]\n",
        "audioemotion_pred=[]\n",
        "# Example usage\n",
        "for i in range(0,len(testdata)):\n",
        "  text = testsentences[i]\n",
        "  video_path = '/content/Videos/VideoFlash/' + testdata[i] + 'flv' #\"/content/Video/1064_IEO_SAD_HI.flv\"\n",
        "  audio_path = '/content/Audio/AudioWAV/'+ testdata[i] + 'wav' #\"/content/Audio/1064_IEO_SAD_HI.wav\"\n",
        "\n",
        "    # Let's assume your text, video, and audio models have predicted the following emotions\n",
        "  textemotion_pred.append(predict_text_emotion(text))#[0.2, 0.3, 0.1, 0.1, 0.2, 0.1]  # Example prediction from the text model\n",
        "  videoemotion_pred.append(predict_video_emotion(video_path))#[0.1, 0.4, 0.1, 0.1, 0.1, 0.2]  # Example prediction from the video model\n",
        "  audioemotion_pred.append(predict_audio_emotion(audio_path))#[0.3, 0.2, 0.2, 0.1, 0.1, 0.1]  # Example prediction from the audio model\n",
        "\n",
        "textemotions=[]\n",
        "videoemotions=[]\n",
        "audioemotions=[]\n",
        "finalemotions=[]\n",
        "def predict(tw,vw,aw):\n",
        "  textemotions.clear()\n",
        "  videoemotions.clear()\n",
        "  audioemotions.clear()\n",
        "  finalemotions.clear()\n",
        "  for i in range(0,len(testdata)):\n",
        "    # Set custom weights for each modality\n",
        "    text_weight = tw\n",
        "    video_weight = vw\n",
        "    audio_weight = aw\n",
        "\n",
        "    # Apply custom weights to each modality's prediction\n",
        "    weighted_text_emotion = text_weight * np.array(textemotion_pred[i])\n",
        "    weighted_video_emotion = video_weight * np.array(videoemotion_pred[i])\n",
        "    weighted_audio_emotion = audio_weight * np.array(audioemotion_pred[i])\n",
        "\n",
        "    # Combine the weighted predictions (you can choose a different method, e.g., averaging)\n",
        "    final_emotion = np.argmax(weighted_text_emotion + weighted_video_emotion + weighted_audio_emotion)\n",
        "\n",
        "    textemotions.append(np.argmax(weighted_text_emotion))\n",
        "    videoemotions.append(np.argmax(weighted_video_emotion))\n",
        "    audioemotions.append(np.argmax(weighted_audio_emotion))\n",
        "    finalemotions.append(final_emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvqZV5tfL0wF",
        "outputId": "9e1aafad-5dec-45e2-d583-8c551c634ca2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#equal weightage to audio and video\n",
        "def getAccuracy():\n",
        "  te=0\n",
        "  ae=0\n",
        "  ve=0\n",
        "  fe=0\n",
        "  for i in range(0,433):\n",
        "    if finalemotion[i] == textemotions[i]:\n",
        "      te= te+1\n",
        "    if finalemotion[i] == audioemotions[i]:\n",
        "      ae= ae+1\n",
        "    if finalemotion[i] == videoemotions[i]:\n",
        "      ve= ve+1\n",
        "    if finalemotion[i] == finalemotions[i]:\n",
        "      fe= fe+1\n",
        "  print(' final emotion : ' + str(fe/433))\n",
        "  print(' final emotion : ' + str(te/433))\n",
        "  print(' final emotion : ' + str(ve/433))\n",
        "  print(' final emotion : ' + str(ae/433))"
      ],
      "metadata": {
        "id": "d_-aPs6eL25F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(1,1,1)\n",
        "getAccuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV5gTNdRL4Us",
        "outputId": "b4a38abb-ef2b-480f-f9b8-e79665488eca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " final emotion : 0.9816666666666667\n",
            " final emotion : 0.8188888888888889\n",
            " final emotion : 0.6227777777777778\n",
            " final emotion : 0.9394444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tep=[]\n",
        "aep=[]\n",
        "vep=[]\n",
        "for i in textemotion_pred:\n",
        "  tep.append(i)\n",
        "for i in videoemotion_pred:\n",
        "  vep.append(i[0])\n",
        "for i in audioemotion_pred:\n",
        "  aep.append(i[0])"
      ],
      "metadata": {
        "id": "gsu9Xt5E5lrQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Example probabilities for each modality\n",
        "text_probabilities = tep\n",
        "audio_probabilities = aep\n",
        "video_probabilities = vep\n",
        "\n",
        "# Ground truth labels for the samples (replace with your actual labels)\n",
        "labels = finalemotion[:1800]\n",
        "\n",
        "# Combine probabilities into a feature matrix\n",
        "X = np.concatenate([text_probabilities, audio_probabilities, video_probabilities], axis=1)\n",
        "\n",
        "# Define a neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, np.array(labels), epochs=100, verbose=0)\n",
        "\n",
        "# Get the learned weights\n",
        "weights = model.get_weights()[0]\n",
        "\n",
        "# Display the learned weights\n",
        "textweight, audioweight, videoweight = weights.flatten()\n",
        "print(\"Learned Weights - Text: {:.3f}, Audio: {:.3f}, Video: {:.3f}\".format(textweight, audioweight, videoweight))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "5tJEjEwzSOQB",
        "outputId": "3e4fe172-f9ab-41bc-f314-5200f329efdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-25b50afdae25>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Display the learned weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtextweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudioweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideoweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learned Weights - Text: {:.3f}, Audio: {:.3f}, Video: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudioweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideoweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tw=np.array(weights.flatten()[:6])\n",
        "aw=np.array(weights.flatten()[6:12])\n",
        "vw=np.array(weights.flatten()[12:])\n",
        "predict(tw,vw,aw) # aw =1.8\n",
        "getAccuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmtvBqYs5Te3",
        "outputId": "bc5cc109-ba0b-443a-93e7-f9b9d7731118"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " final emotion : 0.8013856812933026\n",
            " final emotion : 0.6697459584295612\n",
            " final emotion : 0.6004618937644342\n",
            " final emotion : 0.7759815242494227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlMTcavk6fiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}